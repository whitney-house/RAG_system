# Recipe RAG System  
Inspired by course: [Understanding LLMs](https://cogsciprag.github.io/Understanding-LLMs-course/intro.html)  

## ğŸ“Œ Project Overview  
This project is a cutting-edge **Retrieval-Augmented Generation (RAG)** system designed for **recipe retrieval** and **context-aware response generation**.  
It integrates **Llama** as the core language model, **MiniLM embeddings** for efficient retrieval, and **FAISS** for vector search, all exposed through a high-performance **FastAPI server**.  

âœ… **Tested on MacBook Air M1** â€” Runs smoothly with efficient memory usage!  
âœ… **Easily adaptable** to other domains like **automotive repair, industrial manufacturing, or medical Q&A** â€” just swap datasets and models.  

---

## ğŸš€ Key Features  
- ğŸ” **Advanced RAG Architecture** â€“ Llama LLM + MiniLM embeddings + FAISS retrieval  
- âš¡ **FastAPI-Powered API** â€“ Low-latency, production-ready RESTful service  
- ğŸ› ï¸ **Fully Modular** â€“ Users can easily swap models, embeddings, and datasets  
- ğŸ’» **Optimized for Apple Silicon** â€“ Runs smoothly on **MacBook Air M1** without GPU  
- ğŸ“¦ **Dockerized Deployment** â€“ Ready to deploy with **Docker & Docker Compose**  
- ğŸŒ **React Frontend** â€“ Chat-based UI for recipe exploration  

---

## ğŸ› ï¸ Technology Stack  

| **Component**      | **Technology**                                    |
|--------------------|--------------------------------------------------|
| **Language Model** | Llama (Meta AI)                                  |
| **Vector Search**  | FAISS + LlamaIndex                               |
| **Embeddings**     | `sentence-transformers/all-MiniLM-L6-v2`         |
| **API Framework**  | FastAPI                                          |
| **Frontend**      | JavaScript, React.js                             |
| **Database**      | FAISS for scalable vector search                 |
| **Containerization** | Docker & Docker Compose                       |

---

## ğŸ›ï¸ System Architecture  

### 1ï¸âƒ£ Backend (RAG Core + API Server)  
- **Retrieval**: FAISS + MiniLM embeddings for fast **semantic search**  
- **Generation**: Llama model generates responses with retrieved **context**  
- **API Interface**: FastAPI exposes endpoints for easy **integration**  

### 2ï¸âƒ£ Frontend (React UI)  
- **Conversational chat interface**  
- **Displays AI-generated recipes and contextual responses**  

---

## ğŸ–¼ï¸ Demo Preview  
Below are sample screenshots showcasing the system in action. The images are stored in the `assets/` folder:  

| **Demo**                  | **Description**                          |
|---------------------------|------------------------------------------|
| ![Demo 1](https://github.com/whitney-house/RAG_system/blob/main/fronted/src/assets/demo1.png) | Design          |
| ![Demo 2](https://github.com/whitney-house/RAG_system/blob/main/fronted/src/assets/demo2.png) | Recipe retrieval in action               |
| ![Demo 3](assets/demo3.png](https://github.com/whitney-house/RAG_system/blob/main/fronted/src/assets/demo1.png) | Personalized recipe recommendations   |

---


## ğŸ”§ Future Improvements
âœ… Agent Integration â€“ Adding AI Agents for more complex reasoning and interactions
âœ… Cross-Domain Support â€“ Expand to industrial, automotive, and healthcare applications
âœ… Fine-Tuning Support â€“ Enable custom Llama training for domain-specific use cases
âœ… Enhanced Vector Search â€“ Move beyond FAISS to more scalable solutions
âœ… Optimized for Apple Silicon â€“ Further improvements for M1/M2/M3 chips
## ğŸ“œ License & Usage
This project is open for customizationâ€”feel free to replace models and datasets for your own use.
âš ï¸ Do not use this for commercial purposes without permission. ğŸš€

